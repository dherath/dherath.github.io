<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="apple-mobile-web-app-capable" content="yes"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <title> Implementing Deep Recurrent Neural Networks (RNN) | </title> <meta name="description" content=" post 12 "> <meta name="keywords" content="rnn, RNN, time, series, prediction, deep, learning, recurrent, neural, networks, LSTM, GRU"> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <!-- Social: Facebook / Open Graph --> <meta property="og:type" content="article"> <meta property="article:author" content="Jerome Dinal Herath"> <meta property="article:section" content=""> <meta property="article:tag" content="rnn, RNN, time, series, prediction, deep, learning, recurrent, neural, networks, LSTM, GRU"> <meta property="article:published_time" content="2019-08-18 00:00:00 -0400"> <meta property="og:url" content="http://dinalherath.com/2019/rnn/"> <meta property="og:title" content=" Implementing Deep Recurrent Neural Networks (RNN) | "> <meta property="og:image" content="http://dinalherath.com"> <meta property="og:description" content=" post 12 "> <meta property="og:site_name" content="Jerome Dinal Herath"> <meta property="og:locale" content="en_US"> <!-- Social: Twitter --> <meta name="twitter:card" content=""> <meta name="twitter:site" content=""> <meta name="twitter:title" content=" Implementing Deep Recurrent Neural Networks (RNN) | "> <meta name="twitter:description" content=" post 12 "> <meta name="twitter:image:src" content="http://dinalherath.com"> <!-- Social: Google+ / Schema.org --> <meta itemprop="name" content=" Implementing Deep Recurrent Neural Networks (RNN) | "> <meta itemprop="description" content=" post 12 "> <meta itemprop="image" content="http://dinalherath.com"> <!-- rel prev and next --> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="stylesheet" href="/assets/css/font-awesome.min.css"> <!-- Canonical link tag --> <link rel="canonical" href="http://dinalherath.com/2019/rnn/"> <link rel="alternate" type="application/rss+xml" title="" href="http://dinalherath.com/feed.xml"> <script type="text/javascript"> var disqus_shortname = ''; var _gaq = _gaq || []; _gaq.push(['_setAccount', 'UA-99988883-1']); _gaq.push(['_trackPageview']); (function() { var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })(); </script> </head> <body> <main class="wrapper"> <header class="site-header"> <nav class="nav"> <div class="container"> <h1 class="logo"><a href="/"><span></span></a></h1> <ul class="navbar"> <li><a href="/">About</a></li> <li><a href="/blog">Blog</a></li> <li><a href="/research">Research</a></li> <li><a href="/dinal_cv.pdf">CV</a></li> <!-- <li><a href="/resume">Resume</a></li>--> <!--<li><a href="/contact">Contact</a></li>--> </ul> </div> </nav> </header> <article class="post container" itemscope itemtype="http://schema.org/BlogPosting"> <header class="post-header"> <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <p class="post-meta"><time datetime="2019-08-18T00:00:00-04:00" itemprop="datePublished">Aug 18, 2019</time></p> <h1 class="post-title" itemprop="name headline">Implementing Deep Recurrent Neural Networks (RNN)</h1> </header> <div class="post-content" itemprop="articleBody"> <p><img src="http://dinalherath.com/material/2019/post_12/model_image.jpeg" alt="rnn-image" width="340px" /></p> <p>Hi All! Today I thought of writing an introductory post on implementing <strong>Deep Learning</strong> models using <a href="https://www.tensorflow.org">Tensorflow</a>. In recent years you probably have heard about <em>AI</em> beating players in quite complex games like <a href="https://deepmind.com/research/alphago/">GO</a> and <a href="https://www.theverge.com/2019/4/13/18309459/openai-five-dota-2-finals-ai-bot-competition-og-e-sports-the-international-champion">DOTA</a> and probably thought its really cool. This explosive development in machine intelligence is due to advancements in Deep Learning, which is a branch of machine learning that extends from <em>neural networks</em>.</p> <p>Deep Learning has been used in many application domains from image and video processing to time series forecasting and creating autonomous agents that could say play games. Now, to be very specific I will be talking about a subset of deep learning models that are specifically designed to work with time series data. Referring to the image up top these models can be grouped together into whats called <strong>Recurrent Neural Networks (RNN)</strong>. These are a set models that have the capability to identify temporal correlation in data.</p> <p>To clarify, my post today will not be about explaining how a recurrent neural network works, instead I will walk you through snippets of code that will help you to build your own RNN model. So I am assuming you know somewhat about how RNNs work and the theory behind it and have some understanding about <strong>Tensorflow</strong>. If you don’t know much about deep learning and RNNs these links below are good places to start learning about these models.</p> <ul> <li>The set of free Deep Learning course by <a href="https://cognitiveclass.ai/learn/deep-learning/">Cognitive Class</a>.</li> <li>Free Deep Learning course by <a href="https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187">Udacity</a>.</li> <li>The online version of <a href="http://www.deeplearningbook.org">deeplearningbook</a>.</li> </ul> <p>The RNN I will be explaining today takes in sequences of 50 (T+1 to T+50 where T is the time step) times series values to the immediate past and predicts the future variation based on it. This kind of RNN can be used to predict variations in temperature, humidity, ran fall, signal strength ect. For clarity I will break down my post into three sections. In <strong>Part 1</strong> I will talk about data preprocessing, namely how I convert a univariate time series (i.e. the time series has only one feature) into an appropriate input format to the model. In <strong>Part 2</strong> I will talk about the model itself and finally in <strong>Part 3</strong> I will present the code to run the model.</p> <h4 id="part-1--data-preprocessing">Part 1 : Data Preprocessing</h4> <p>Data preprocessing is a very important part in many Machine learning applications. And more often than not, the most important part of applying models is to understand the data so that you know to pick the best model for your data. Once you pick the model, the data needs to be preprocessed in a way the model understands it. For this example, referring to the image above the model takes in sequences of data. Lets say we have a time series of 1000 values [1,2,3,…,999,1000]. The RNN model needs input as sequences of data where the model will learn the temporal behavior of each sequence. In this case if say the sequence length is 50, then the model needs sequences [1-50],[2-51],[3-52]… with unit time step for all the data.</p> <p>The function <strong>getData</strong> converts a list of univariate time series values into a sequences of data used for both training and testing the model. The input parameters are the <em>filename</em> use to load data, the <em>x_length</em> the size of the input sequence (as per the figure default is 50), the <em>y_length</em> the number of future predictions made by the RNN and finally the <em>percentage</em> between training and test data separation. Usually and 80:20 split for training:testing is used in most models so <em>percentage=0.8</em> usually works. This function returns the sequences used for training and testing and the predictor labels as well. The helper functions <strong>openFile</strong> and <strong>sampleData</strong> used within <strong>getData</strong> reads data from file and creates the sequences respectively. I usually create a separate python file <strong>DataPreprocessor.py</strong> and use the functions herewith to preprocess the input data.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Main Function to preprocess dataset ---------------------------------</span>
<span class="k">def</span> <span class="nf">getData</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="n">x_length</span><span class="p">,</span><span class="n">y_length</span><span class="p">,</span><span class="n">percentage</span><span class="p">):</span>
    <span class="s">""" converts a univariete time series into a sequences of data"""</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">openFile</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="c"># open the file and get data</span>
    <span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">percentage</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="c"># find the number of samples for training</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">train_size</span><span class="p">]</span> <span class="c"># get training sample</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">train_size</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c"># get testing sample</span>
    <span class="n">X_Train</span><span class="p">,</span><span class="n">Y_Train</span> <span class="o">=</span> <span class="n">sampleData</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span><span class="n">x_length</span><span class="p">,</span><span class="n">y_length</span><span class="p">)</span> <span class="c"># get the [X:input,Y:output] for training</span>
    <span class="n">X_Test</span><span class="p">,</span><span class="n">Y_Test</span> <span class="o">=</span> <span class="n">sampleData</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span><span class="n">x_length</span><span class="p">,</span><span class="n">y_length</span><span class="p">)</span>  <span class="c"># get the [X:input,Y:output] for testing</span>
    <span class="k">return</span> <span class="n">X_Train</span><span class="p">,</span><span class="n">Y_Train</span><span class="p">,</span><span class="n">X_Test</span><span class="p">,</span><span class="n">Y_Test</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Helper Functions ---------------------------------------------------</span>
<span class="k">def</span> <span class="nf">openFile</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="s">""" loads the input data from file"""</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">words</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
            <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">data</span>


<span class="k">def</span> <span class="nf">sampleData</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="n">x_length</span><span class="p">,</span><span class="n">y_length</span><span class="p">):</span>
    <span class="s">""" generates a sequence of data forom a a single univariete stream"""</span>
    <span class="n">x_data_limit</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">x_length</span><span class="o">+</span><span class="n">y_length</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x_data_limit</span><span class="p">):</span>
        <span class="n">temp_x</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x_length</span><span class="p">):</span>
            <span class="n">temp_x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">j</span><span class="p">])</span>
        <span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">temp_x</span><span class="p">)</span>
        <span class="n">temp_y</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_length</span><span class="p">):</span>
            <span class="n">temp_y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="n">x_length</span><span class="o">+</span><span class="n">j</span><span class="p">])</span>
        <span class="n">Y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">temp_y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span><span class="n">Y</span>
</code></pre></div></div> <h4 id="part-2--the-rnn-model">Part 2 : The RNN Model</h4> <p>Now to the RNN model itself–In the code below the python function <em>graph()</em> defines the structure of the model shown in the image above. The first few lines of code in the function, initially reset the graph in Tensorflow. This is done to ensure that a pre-loaded graph is cleaned before creation of the RNN graph. This is followed by instantiation of the variables for the <em>weights</em> and <em>bias</em> of the final prediction layer <script type="math/tex">\hat{Y}_{T}</script>.</p> <p>The RNN model has multiple components defined in its own respective variable scope. The scope <em>rnn</em> defines the model structure that processes each temporal value in the sequence. The scope <em>cells</em> within <em>rnn</em> defines the architecture for a single unit used in the RNN. If you want to use more sophisticated structures like <strong>LSTM,GRU</strong> this is the code segment that needs to be changed. The scope <em>loss</em> defines the loss function that is used in the model, for this example I have used the <code class="highlighter-rouge">root-mean-squared error</code> and finally the scope <em>Optimizer</em> defines the function used to reduce the loss for each training epoch.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'TF_CPP_MIN_LOG_LEVEL'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'2'</span>
<span class="c"># --</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="k">def</span> <span class="nf">graph</span><span class="p">():</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span> <span class="c"># reset the previous graph    </span>
    <span class="n">global_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_value</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span> <span class="s">"global_step"</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">collections</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">GLOBAL_STEP</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">GLOBAL_VARIABLES</span><span class="p">])</span>   
    <span class="c"># initiliazing the weights</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'out'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">'Weights_out'</span><span class="p">,</span><span class="n">shape</span> <span class="o">=</span><span class="p">[</span><span class="n">hidden_size</span><span class="p">,</span><span class="n">y_length</span><span class="p">],</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="n">random_seed</span><span class="p">))</span>
    <span class="p">}</span>
    <span class="c"># intializing the biases</span>
    <span class="n">biases</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s">'out'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">'Biases_out'</span><span class="p">,</span><span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_length</span><span class="p">],</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
    <span class="p">}</span>
    <span class="c"># initilizing the rnn model</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'rnn'</span><span class="p">):</span>
        <span class="c">#model inputs</span>
        <span class="n">rnn_input</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">None</span><span class="p">,</span><span class="n">input_dim</span><span class="p">),</span> <span class="n">name</span> <span class="o">=</span> <span class="s">"rnn_inp"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x_length</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="c">#model outputs</span>
        <span class="n">rnn_output</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">None</span><span class="p">,</span><span class="n">output_dim</span><span class="p">),</span> <span class="n">name</span> <span class="o">=</span> <span class="s">"rnn_out"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_length</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="c"># stacking multiple RNN cells together</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">"Cell"</span><span class="p">):</span>
            <span class="n">cells</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_stacked_layers</span><span class="p">):</span>
                <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'RNN_{}'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)):</span>
                    <span class="n">cells</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicRNNCell</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">))</span>
            <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">(</span><span class="n">cells</span><span class="p">)</span>

        <span class="n">model_output</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">static_rnn</span><span class="p">(</span><span class="n">cell</span><span class="p">,</span><span class="n">rnn_input</span><span class="p">,</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="n">final_rnn_output</span> <span class="o">=</span> <span class="n">model_output</span><span class="p">[</span><span class="n">y_length</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">final_rnn_output</span><span class="p">,</span><span class="n">weights</span><span class="p">[</span><span class="s">'out'</span><span class="p">])</span> <span class="o">+</span> <span class="n">biases</span><span class="p">[</span><span class="s">'out'</span><span class="p">]</span>
    <span class="c"># defining the loss</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'loss'</span><span class="p">):</span>
        <span class="n">output_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squared_difference</span><span class="p">(</span><span class="n">output</span><span class="p">,</span><span class="n">rnn_output</span><span class="p">))</span>
    <span class="c"># defining the optimizer</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s">'Optimizer'</span><span class="p">):</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">optimize_loss</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">output_loss</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span><span class="n">global_step</span><span class="o">=</span><span class="n">global_step</span><span class="p">,</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'Adam'</span><span class="p">)</span>

    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">rnn_input</span><span class="o">=</span><span class="n">rnn_input</span><span class="p">,</span><span class="n">rnn_output</span><span class="o">=</span><span class="n">rnn_output</span><span class="p">,</span><span class="n">train_op</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span><span class="n">loss</span><span class="o">=</span><span class="n">output_loss</span><span class="p">,</span><span class="n">saver</span><span class="o">=</span><span class="n">saver</span><span class="p">,</span><span class="n">output</span><span class="o">=</span><span class="n">output</span><span class="p">)</span>

</code></pre></div></div> <h4 id="part-3--model-execution">Part 3 : Model Execution</h4> <p>In terms of model execution, the code here starts by setting the hyper parameters of the RNN model. Afterwards the code calls the data preprocessing functionality described in <strong>Part 1</strong> to obtain the training sequences. I have defined a training cycle count or <em>epochs</em> of a 1000. This stopping criterion is a highly subjective value and depends on the actual dataset you’ll use.</p> <p>The actual execution of the model starts from the code segment <code class="highlighter-rouge">with tf.Session() as sess:</code>. Within the Tensorflow session, the first part of the code implements the training process where we call the models loss function and optimizer at each epoch. I have made print statements for every <script type="math/tex">100^{th}</script> turn to display the variation of the loss as the model trains more and mode. In practice you will probably notice that models tend to have drastic reductions in loss at the very beginning, and tend to have a slower reduction rate as more time goes by. Once the training is complete, the test data is used to evaluate the final predictive performance. For ease of presentation, I have grouped the training and testing in one Tensorflow session, but it doesn’t have to be so.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'TF_CPP_MIN_LOG_LEVEL'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'2'</span>
<span class="c"># --</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">preprocessor</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">filename</span> <span class="o">=</span> <span class="s">"data.txt"</span>
<span class="c"># ------- RNN model configurations ------------</span>
<span class="n">x_length</span> <span class="o">=</span> <span class="mi">50</span> <span class="c"># input size</span>
<span class="n">y_length</span> <span class="o">=</span> <span class="mi">20</span> <span class="c"># prediction size</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="c"># the learning rate parameter</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">50</span> <span class="c"># the number of hidden units</span>
<span class="n">random_seed</span> <span class="o">=</span> <span class="mi">100</span> <span class="c"># a random seed for initializing the values</span>
<span class="n">num_stacked_layers</span> <span class="o">=</span> <span class="mi">4</span> <span class="c"># the depth of our model</span>
<span class="n">input_dim</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">output_dim</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">train_test_seperation</span> <span class="o">=</span> <span class="mf">0.6</span> <span class="c"># 60% - train data, 40% - all test (validation - 20%, test - 20%)</span>
<span class="n">X_train</span><span class="p">,</span><span class="n">Y_train</span><span class="p">,</span><span class="n">X_T</span><span class="p">,</span><span class="n">Y_T</span> <span class="o">=</span> <span class="n">getData</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span><span class="n">x_length</span><span class="p">,</span><span class="n">y_length</span><span class="p">,</span><span class="n">train_test_seperation</span><span class="p">)</span>

<span class="n">sz</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_T</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span> <span class="c"># split the generated test set 50-50 for validationa dn testing</span>
<span class="c">#print sz</span>

<span class="n">X_train_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> <span class="c"># trainign set</span>
<span class="n">Y_train_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>

<span class="n">X_validate_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_T</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">sz</span><span class="p">])</span> <span class="c"># validation set</span>
<span class="n">Y_validate_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y_T</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">sz</span><span class="p">])</span>

<span class="n">X_test_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_T</span><span class="p">[</span><span class="n">sz</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c"># testing set</span>
<span class="n">Y_test_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y_T</span><span class="p">[</span><span class="n">sz</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="c">#-----------------------------------------------</span>
<span class="c">#            RNN - Model</span>
<span class="c">#-----------------------------------------------</span>
<span class="s">"""
 NOTE : you can put the model code in Part 2 right here
"""</span>
<span class="c">#-----------------------------------------------</span>
<span class="c">#            RUN</span>
<span class="c">#-----------------------------------------------</span>
<span class="n">rnn_model</span> <span class="o">=</span> <span class="n">graph</span><span class="p">()</span> <span class="c"># From the Function in Part 2</span>
<span class="n">ep</span> <span class="o">=</span> <span class="mi">0</span> <span class="c"># a counter for the number of iterations the model passes the datasets</span>
<span class="n">EPOCH_LIMIT</span> <span class="o">=</span> <span class="mi">1000</span> <span class="c"># a limiting factor to num.iterations</span>
<span class="n">CONTINUE_FLAG</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">Y_found</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># final predictions for test data</span>
<span class="n">train_loss</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># loss values for training</span>
<span class="n">validate_loss</span> <span class="o">=</span> <span class="p">[]</span> <span class="c"># loss values for validation set</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="k">print</span> <span class="s">" -- tensorflow session started --"</span>
    <span class="n">init</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="c">#---------------------------------------------------------</span>
    <span class="k">print</span> <span class="s">" -- model: training started --"</span>
    <span class="k">while</span> <span class="n">CONTINUE_FLAG</span><span class="p">:</span>
        <span class="c"># trains on the training data</span>
        <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">rnn_model</span><span class="p">[</span><span class="s">'rnn_input'</span><span class="p">][</span><span class="n">t</span><span class="p">]:</span><span class="n">X_train_data</span><span class="p">[:,</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">input_dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x_length</span><span class="p">)}</span>
        <span class="n">feed_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">rnn_model</span><span class="p">[</span><span class="s">'rnn_output'</span><span class="p">][</span><span class="n">t</span><span class="p">]:</span><span class="n">Y_train_data</span><span class="p">[:,</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">output_dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_length</span><span class="p">)})</span>
        <span class="c">#runs the model on the tarining data</span>
        <span class="n">train_t</span><span class="p">,</span><span class="n">loss_t</span><span class="p">,</span><span class="n">out_t</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">rnn_model</span><span class="p">[</span><span class="s">'train_op'</span><span class="p">],</span><span class="n">rnn_model</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span><span class="n">rnn_model</span><span class="p">[</span><span class="s">'output'</span><span class="p">]],</span><span class="n">feed_dict</span><span class="p">)</span> <span class="c">#trains the model</span>
        <span class="n">train_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_t</span><span class="p">)</span> <span class="c"># appends value to list</span>

        <span class="c"># runs on the validation set</span>
        <span class="n">feed_dict2</span> <span class="o">=</span> <span class="p">{</span><span class="n">rnn_model</span><span class="p">[</span><span class="s">'rnn_input'</span><span class="p">][</span><span class="n">t</span><span class="p">]:</span><span class="n">X_validate_data</span><span class="p">[:,</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">input_dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x_length</span><span class="p">)}</span>
        <span class="n">feed_dict2</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">rnn_model</span><span class="p">[</span><span class="s">'rnn_output'</span><span class="p">][</span><span class="n">t</span><span class="p">]:</span><span class="n">Y_validate_data</span><span class="p">[:,</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">output_dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_length</span><span class="p">)})</span>  
        <span class="c"># runs the model on the validation data         </span>
        <span class="n">validation_loss_t</span><span class="p">,</span><span class="n">validation_out_t</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">rnn_model</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span><span class="n">rnn_model</span><span class="p">[</span><span class="s">'output'</span><span class="p">]],</span><span class="n">feed_dict2</span><span class="p">)</span> <span class="c"># runs on the validation data</span>
        <span class="n">validate_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">validation_loss_t</span><span class="p">)</span> <span class="c"># appends value to list</span>
        <span class="c">#print the training and the validation loss every 100 turns</span>
        <span class="k">if</span> <span class="n">ep</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span> <span class="n">ep</span><span class="p">,</span><span class="s">" train loss: "</span><span class="p">,</span><span class="n">loss_t</span><span class="p">,</span><span class="s">" validation loss: "</span><span class="p">,</span><span class="n">validation_loss_t</span>
        <span class="k">if</span> <span class="n">ep</span> <span class="o">&gt;</span> <span class="n">EPOCH_LIMIT</span><span class="p">:</span>
            <span class="n">CONTINUE_FLAG</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="n">ep</span> <span class="o">=</span> <span class="n">ep</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c">#-----------------------</span>
    <span class="k">print</span> <span class="s">" -- model: training stopped --"</span>
    <span class="c">#----------------------------------------------------------</span>
    <span class="c"># once trianing is complete, run the model on the test dataset</span>
    <span class="n">feed_dict3</span> <span class="o">=</span> <span class="p">{</span><span class="n">rnn_model</span><span class="p">[</span><span class="s">'rnn_input'</span><span class="p">][</span><span class="n">t</span><span class="p">]:</span><span class="n">X_test_data</span><span class="p">[:,</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">input_dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x_length</span><span class="p">)}</span>

    <span class="n">Y_temp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test_data</span><span class="p">),</span><span class="n">y_length</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="nb">float</span><span class="p">)</span>
    <span class="n">feed_dict3</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="n">rnn_model</span><span class="p">[</span><span class="s">'rnn_output'</span><span class="p">][</span><span class="n">t</span><span class="p">]:</span><span class="n">Y_temp</span><span class="p">[:,</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">output_dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_length</span><span class="p">)})</span>

    <span class="n">test_out_t</span><span class="p">,</span> <span class="n">test_loss_t</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">rnn_model</span><span class="p">[</span><span class="s">'output'</span><span class="p">],</span><span class="n">rnn_model</span><span class="p">[</span><span class="s">'loss'</span><span class="p">]],</span><span class="n">feed_dict3</span><span class="p">)</span> <span class="c"># runs on the test</span>

    <span class="n">Y_found</span> <span class="o">=</span> <span class="n">test_out_t</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="c"># final product</span>
    <span class="k">print</span> <span class="s">" -- session complete --"</span>
</code></pre></div></div> <p>There you go, a speedy run through on how to build a RNN model in Tensorflow. Note that this code in question is not designed GPUs, so the actual speed for training might be pretty slow in practice. Its possible to refactor this code to work with GPUs, but thats a post for another time.</p> <h5 id="so-until-next-time">So until next time,</h5> <h5 id="cheers">Cheers!</h5> <p><strong>Prev: <a href="http://dinalherath.com/2019/ta-tools/">Making TA-life easier : Bash scripts for grading</a></strong></p> <aside class="share"> <p>If you liked this article and think others should read it, please <a href="http://twitter.com/share?text=Implementing Deep Recurrent Neural Networks (RNN)&amp;url=http://dinalherath.com/2019/rnn/&amp;via=" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">share it on Twitter <i class="fa fa-twitter" aria-hidden="true" style="color:#00aced"></i></a> or <a href='https://www.facebook.com/sharer/sharer.php?u='+url; onclick="window.open(this.href, 'sharer', 'toolbar=0,status=0,width=550,height=235');return false;">Facebook <i class="fa fa-facebook-square" aria-hidden="true" style="color:#3b5998"></i></a>.</p> </aside> </div> </article> <!-- --> <footer class="site-footer"> <!--<link rel="stylesheet" href="/assets/icons/academicons-1.8.0/css/academicons.css"/>--> <div class="container"> <small class="block"><!--&lt;/&gt; <a href="http://github.com/heiswayi/thinkspace" title="a minimalist Jekyll theme for technical writing">Thinkspace theme</a> by <a href="http://heiswayi.github.io">Heiswayi Nrird</a>. |--><i class="fa fa-copyright"></i> 2017-2019 Jerome Dinal Herath</small> <a href="mailto:dinal.bing@gmail.com"><i class="fa fa-envelope" style="font-size:21px;color:#F15B3D;"></i></a> <a href="https://www.facebook.com/dinalHerath" target="_blank"><i class="fa fa-facebook-square" style="font-size:22px;color:#F15B3D"></i></a> <a href="https://github.com/dherath" target="blank"><i class="fa fa-github-square" style="font-size:22px;color:#F15B3D"></i></a> <a href="https://www.linkedin.com/in/jerome-dinal-herath-bba3b0148/" target="blank"><i class="fa fa-linkedin-square" style="font-size:22px;color:#F15B3D"></i></a> <a href="/feed.xml" target="_blank"><i class="fa fa-rss-square" style="font-size:22px;color:#F15B3D"></i></a> <a href="https://www.researchgate.net/profile/Jerome_Dinal_Herath" target="blank"> <i style="font-size:20px;color:#F15B3D;font-weight:bold;"> RG </i></a> </div> </footer> </main> </body> </html>
